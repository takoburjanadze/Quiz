{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea5f828-e68f-45c0-b165-686272f92fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing rows with problematic values...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8946 - loss: 0.3443 - val_accuracy: 0.9866 - val_loss: 0.0516\n",
      "Epoch 2/10\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0428 - val_accuracy: 0.9885 - val_loss: 0.0405\n",
      "Epoch 3/10\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9902 - loss: 0.0358 - val_accuracy: 0.9908 - val_loss: 0.0378\n",
      "Epoch 4/10\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9914 - loss: 0.0328 - val_accuracy: 0.9905 - val_loss: 0.0346\n",
      "Epoch 5/10\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9913 - loss: 0.0323 - val_accuracy: 0.9913 - val_loss: 0.0322\n",
      "Epoch 6/10\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0285 - val_accuracy: 0.9905 - val_loss: 0.0321\n",
      "Epoch 7/10\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 0.0272 - val_accuracy: 0.9911 - val_loss: 0.0303\n",
      "Epoch 8/10\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9929 - loss: 0.0268 - val_accuracy: 0.9917 - val_loss: 0.0299\n",
      "Epoch 9/10\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0261 - val_accuracy: 0.9916 - val_loss: 0.0308\n",
      "Epoch 10/10\n",
      "\u001b[1m496/496\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9928 - loss: 0.0250 - val_accuracy: 0.9915 - val_loss: 0.0301\n",
      "\u001b[1m992/992\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0306\n",
      "Test Loss: 0.0300\n",
      "Test Accuracy: 0.9915\n"
     ]
    }
   ],
   "source": [
    "import ipaddress\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv(\"C:/Users/Lenovo/Downloads/Darknet.csv\")\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop([\"Flow ID\", \"Timestamp\", \"Label2\"], axis=1)\n",
    "\n",
    "# Drop rows with missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert IP addresses to integers\n",
    "df['Src IP'] = df['Src IP'].apply(lambda x: int(ipaddress.ip_address(x)))\n",
    "df['Dst IP'] = df['Dst IP'].apply(lambda x: int(ipaddress.ip_address(x)))\n",
    "\n",
    "# Encode the label column\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label1'] = label_encoder.fit_transform(df['Label1'])\n",
    "\n",
    "# Save the preprocessed dataset\n",
    "df.to_csv(\"processed.csv\", index=False)\n",
    "\n",
    "# Identify and handle any problematic values in the dataset\n",
    "problematic_columns = []\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == np.float64 or df[col].dtype == np.int64:\n",
    "        max_value = df[col].max()\n",
    "        min_value = df[col].min()\n",
    "        if max_value == np.inf or min_value == -np.inf:\n",
    "            problematic_columns.append(col)\n",
    "\n",
    "# Remove rows with problematic values\n",
    "if problematic_columns:\n",
    "    print(\"Removing rows with problematic values...\")\n",
    "    df = df[~df[problematic_columns].isin([np.inf, -np.inf]).any(axis=1)]\n",
    "\n",
    "# Split features and label\n",
    "features = df.drop(['Label1'], axis=1)\n",
    "label = df['Label1']\n",
    "\n",
    "# Scale the features using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Save scaled dataset\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=features.columns)\n",
    "scaled_df['Label1'] = label\n",
    "scaled_df.to_csv(\"scaled3.csv\", index=False)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features, label, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(250, activation='relu', input_shape=(scaled_features.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile \n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=256, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Printing the accuracy\n",
    "print(f'Test Loss: {loss:.4f}')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "with open('accuracy3.txt', 'w') as f:\n",
    "    f.write(f'Test Loss: {loss:.4f}\\n')\n",
    "    f.write(f'Test Accuracy: {accuracy:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b21b1339-213b-43c7-95cb-06ebc5c7edb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Src IP  Src Port    Dst IP  Dst Port  Protocol  Flow Duration  \\\n",
      "0  0.047326  0.872188  0.844420  0.006760  0.352941       0.000002   \n",
      "1  0.047326  0.872204  0.844420  0.006760  0.352941       0.000003   \n",
      "2  0.047326  0.872219  0.844420  0.006760  0.352941       0.000004   \n",
      "3  0.047326  0.749748  0.289938  0.006760  0.352941       0.000003   \n",
      "4  0.047326  0.529450  0.678274  0.294575  0.352941       0.089820   \n",
      "\n",
      "   Total Fwd Packet  Total Bwd packets  Total Length of Fwd Packet  \\\n",
      "0          0.000000           0.000002                    0.000000   \n",
      "1          0.000000           0.000002                    0.000000   \n",
      "2          0.000000           0.000002                    0.000000   \n",
      "3          0.000000           0.000002                    0.000000   \n",
      "4          0.002477           0.000850                    0.000084   \n",
      "\n",
      "   Total Length of Bwd Packet  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
      "0                     0.00000  ...          0.454545          0.0         0.0   \n",
      "1                     0.00000  ...          0.454545          0.0         0.0   \n",
      "2                     0.00000  ...          0.454545          0.0         0.0   \n",
      "3                     0.00000  ...          0.454545          0.0         0.0   \n",
      "4                     0.00001  ...          0.454545          0.0         0.0   \n",
      "\n",
      "   Active Max  Active Min  Idle Mean      Idle Std  Idle Max  Idle Min  Label1  \n",
      "0         0.0         0.0   0.000000  0.000000e+00  0.000000  0.000000     0.0  \n",
      "1         0.0         0.0   0.000000  0.000000e+00  0.000000  0.000000     0.0  \n",
      "2         0.0         0.0   0.000000  0.000000e+00  0.000000  0.000000     0.0  \n",
      "3         0.0         0.0   0.000000  0.000000e+00  0.000000  0.000000     0.0  \n",
      "4         0.0         0.0   0.984767  3.026911e-09  0.984767  0.984767     0.0  \n",
      "\n",
      "[5 rows x 82 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the scaled dataset\n",
    "scaled_df = pd.read_csv(\"scaled3.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(scaled_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c90b38-aa13-4242-8047-3664e46de25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 'scaled3.csv' file is located at: C:\\Users\\Lenovo\\scaled3.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Check if the file exists in the current directory or its subdirectories\n",
    "file_found = False\n",
    "for root, dirs, files in os.walk(current_directory):\n",
    "    if \"scaled3.csv\" in files:\n",
    "        file_path = os.path.join(root, \"scaled3.csv\")\n",
    "        print(f\"The 'scaled3.csv' file is located at: {file_path}\")\n",
    "        file_found = True\n",
    "        break\n",
    "\n",
    "if not file_found:\n",
    "    print(\"The 'scaled3.csv' file was not found in the current directory or its subdirectories.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ffac8f-3955-49e6-bbdb-8ac53e50f849",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
